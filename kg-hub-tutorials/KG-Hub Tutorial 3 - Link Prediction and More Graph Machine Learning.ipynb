{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae906ae",
   "metadata": {
    "id": "cae906ae"
   },
   "source": [
    "# KG-Hub Tutorial 3 - Link Prediction and More Graph Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255d9f4",
   "metadata": {
    "id": "2255d9f4"
   },
   "source": [
    "This notebook serves as a practical guide to advanced KG-Hub features and resources. A brief review of the Getting Started tutorial notebook is not a strict prerequisite but may be helpful.  \n",
    "\n",
    "This notebook also assumes you are in a Linux environment, but Google Colab is an option as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cc3a0",
   "metadata": {},
   "source": [
    "Here's an example question for our use case: which foods may impact DNA repair pathways? It's a broad question with many possible answers, or no answers at all. A KG may hold some clues. We don't want to be entirely reliant on existing data, however: starting with sets of chemicals, foods, and biological pathways, we can perform link prediction to predict additional connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316c89d",
   "metadata": {
    "id": "f316c89d"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40629ab9",
   "metadata": {
    "id": "40629ab9"
   },
   "source": [
    "First, we'll install the requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c344976",
   "metadata": {
    "id": "4c344976"
   },
   "outputs": [],
   "source": [
    "!pip install kgx\n",
    "!pip install kghub-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uhYo2aVBaWe4",
   "metadata": {
    "id": "uhYo2aVBaWe4"
   },
   "source": [
    "Now we need to set up two things for KGX to work properly:\n",
    "* A download config file\n",
    "* A merge config file\n",
    "\n",
    "In practice, we may need to write a new transform for each new source, but all of the sources we'll use here are conveniently already available as KGX node and edge files on KG-Hub.\n",
    "\n",
    "We'll download five sources. Two are ontologies available through the KG-OBO project on KG-Hub: FOODON, a food ontology, and CHEBI, a chemical ontology. The other sources are sets of preprocessed [Reactome](https://reactome.org) pathways, connections between those pathways, and mappings between those pathways and chemicals. They're all defined in a dictionary below, with the name of each source as its key and a list of one or more source URLs as its value. We've also defined a set of local filenames, as we know what the compressed ontology files should contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dp81ZNcvb5Qn",
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1654291963120,
     "user": {
      "displayName": "Harry Caufield",
      "userId": "03176428528134146285"
     },
     "user_tz": 240
    },
    "id": "Dp81ZNcvb5Qn"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./\" # Just the current directory, though in practice it would be something like data/raw/\n",
    "sources = {\"foodon\":[\"https://kg-hub.berkeleybop.io/kg-obo/foodon/2022-02-01/foodon_kgx_tsv.tar.gz\"],\n",
    "           \"chebi\":[\"https://kg-hub.berkeleybop.io/kg-obo/chebi/210/chebi_kgx_tsv.tar.gz\"],\n",
    "           \"chebi2reactome\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/chebi2reactome_edges.tsv\",\n",
    "                             \"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/chebi2reactome_nodes.tsv\"],\n",
    "           \"reactome_pathways\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/reactomepathways_nodes.tsv\"],\n",
    "           \"reactome_relations\":[\"https://kg-hub.berkeleybop.io/kg-idg/20220601/transformed/reactome/reactomepathwaysrelation_edges.tsv\"]}\n",
    "local_filepaths = {\"foodon\":[\"foodon_kgx_tsv_edges.tsv\",\n",
    "                            \"foodon_kgx_tsv_nodes.tsv\"],\n",
    "           \"chebi\":[\"chebi_kgx_tsv_edges.tsv\",\n",
    "                    \"chebi_kgx_tsv_nodes.tsv\"],\n",
    "           \"chebi2reactome\":[\"chebi2reactome_edges.tsv\",\n",
    "                             \"chebi2reactome_nodes.tsv\"],\n",
    "           \"reactome_pathways\":[\"reactomepathways_nodes.tsv\"],\n",
    "           \"reactome_relations\":[\"reactomepathwaysrelation_edges.tsv\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jpdRBj8afOrE",
   "metadata": {
    "id": "jpdRBj8afOrE"
   },
   "source": [
    "There is an example of a KGX download config file [here](https://github.com/Knowledge-Graph-Hub/kg-dtm-template/blob/master/download.yaml), but it's easy to assemble from scratch with something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pynXk66VfaOt",
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1654292390036,
     "user": {
      "displayName": "Harry Caufield",
      "userId": "03176428528134146285"
     },
     "user_tz": 240
    },
    "id": "pynXk66VfaOt"
   },
   "outputs": [],
   "source": [
    "source_data = []\n",
    "for source in sources:\n",
    "  for url in sources[source]:\n",
    "    local_name = url.rpartition('/')[-1]\n",
    "    source_data.append({\"url\":url,\n",
    "                        \"local_name\":local_name})\n",
    "\n",
    "with open(\"download.yaml\", \"w\") as dl_config:\n",
    "  yaml.dump(source_data, dl_config, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H_UK6orMgwuc",
   "metadata": {
    "id": "H_UK6orMgwuc"
   },
   "source": [
    "Now we may use the config file with the `kghub-downloader` to download all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7L1P6k8tg3a4",
   "metadata": {
    "id": "7L1P6k8tg3a4"
   },
   "outputs": [],
   "source": [
    "!downloader download.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf36cf",
   "metadata": {},
   "source": [
    "Decompress the compressed sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat *.tar.gz | tar zxvf - -i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f7b89",
   "metadata": {},
   "source": [
    "Next step: set up a merge config file. Our sources are already in the expected KGX graph format, so no transformation is necessary.\n",
    "\n",
    "See the [example merge config](https://github.com/Knowledge-Graph-Hub/kg-dtm-template/blob/master/merge.yaml) in this repository for further inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = {\"configuration\":{\"output_directory\":data_dir,\n",
    "                              \"checkpoint\":\"false\"\n",
    "                              },\n",
    "              \"merged_graph\":{\"name\":\"tutorial_graph\",\n",
    "                              \"source\":{},\n",
    "                              \"operations\":[{\"name\": \"kgx.graph_operations.summarize_graph.generate_graph_stats\",\n",
    "                                        \"args\":{\"graph_name\":\"tutorial_graph\",\n",
    "                                        \"filename\":\"merged_graph_stats.yaml\"\n",
    "                                                }\n",
    "                                                }\n",
    "                                                ],\n",
    "                                \"destination\":{\"merged-kg-tsv\":{\"format\":\"tsv\",\n",
    "                                              \"filename\": \"merged-kg\"}\n",
    "                                                },            \n",
    "                                }\n",
    "                }\n",
    "\n",
    "for source in local_filepaths:\n",
    "  merge_data[\"merged_graph\"][\"source\"][source] = {\"name\":source,\n",
    "                                                  \"input\":{\"format\":\"tsv\",\n",
    "                                                          \"filename\":local_filepaths[source]}\n",
    "                                                  }\n",
    "\n",
    "with open(\"merge.yaml\", \"w\") as merge_config:\n",
    "  yaml.dump(merge_data, merge_config, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wWbNYTkRZ1Qz",
   "metadata": {
    "id": "wWbNYTkRZ1Qz"
   },
   "source": [
    "## KG Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d280092",
   "metadata": {},
   "source": [
    "The data files are all here and the configuration files are ready. We may now use `kgx` to assemble a single set of nodes and edges from them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aeee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgx.cli.cli_utils import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a moment. You've probably been sitting for too long - go take a walk for a few minutes.\n",
    "merged_graph = merge(\"merge.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d92e7",
   "metadata": {},
   "source": [
    "If everything went as expected, the merged KG will be in `merged-kg_edges.tsv` and `merged-kg_nodes.tsv`. There will also be a `merged_graph_stats.yaml` detailing the new graph contents. \n",
    "\n",
    "A brief aside - there's an alternative merge approach called `cat-merge`. [The package is here](https://github.com/monarch-initiative/cat-merge) and an example of its use may be found in KG-Bioportal [here](https://github.com/ncbo/kg-bioportal/blob/main/kg_bioportal/merge_utils/merge_kg.py).\n",
    "\n",
    "Let's take a quick look at the stats file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2324362",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged_graph_stats.yaml\") as yaml_file:\n",
    "    config = yaml.load(yaml_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all edges in the graph\n",
    "print(config[\"edge_stats\"][\"total_edges\"])\n",
    "\n",
    "# Count of all nodes in the graph\n",
    "print(config[\"node_stats\"][\"total_nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of nodes are in the graph?\n",
    "for category in config[\"node_stats\"][\"node_categories\"]:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee332cb",
   "metadata": {},
   "source": [
    "Nodes in ontologies and data sources are assigned appropriate Biolink Model categories whenever possible. Those assigned `NamedThing` may still belong to a more detailed category, but assigning such a category may be challenging.\n",
    "\n",
    "Now let's take a look at the graph contents to begin examining how they may answer our questions.\n",
    "\n",
    "Let's get a set of all relations between food entries in FOODON and chemical entries in CHEBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3587415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep FOODON merged-kg_edges.tsv | grep CHEBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0f894",
   "metadata": {},
   "source": [
    "The \"subject, predicate, and object\" of each relation are found in the second, third, and fourth columns, respectively.\n",
    "I'll save you some trouble: every relation like `CHEBI:XXXXX    biolink:subclass_of FOODON:03412972` is just saying \"this chemical is a [food additive](https://www.ebi.ac.uk/ols/ontologies/foodon/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FFOODON_03412972)\". There are several different *types* of relations in this set, however. We can get a quick idea about those types by looking at the `merged_graph_stats.yaml` KGX has prepared for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -n '/count_by_predicates/,/count_by_spo/p' merged_graph_stats.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b73ee5",
   "metadata": {},
   "source": [
    "We can see, for example, that there are >93 thousand \"participates_in\" relations. Let's see what the participants in these graph edges are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A 1 \"participates_in\" merged_graph_stats.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7cd69",
   "metadata": {},
   "source": [
    "So these are our connections between chemicals and pathways. The same counts appear multiple times because each node may have more than one category (e.g., a ChemicalEntity is also a NamedThing).\n",
    "\n",
    "Continue to the next section for some examples of how to learn more about the new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906f0ff",
   "metadata": {},
   "source": [
    "## Loading Graphs with `GraPE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4862d",
   "metadata": {},
   "source": [
    "The `GraPE` library includes a substantial array of tools for working with graph data, generating reports and plots about graph contents, and preparing graph representations. We'll start by loading the graph from the previous section, then we'll get more details about its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grape -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3fc0e",
   "metadata": {},
   "source": [
    "Once the next block completes, it will output a long text report about the graph's properties and a variety of its \"topological oddities\". These don't mean anything is intrinsically *wrong* with the graph - rather, they are features of the data we have used to construct the graph. In some cases, for example, a CHEBI entry may be present within our imported data despite being deleted from the dataset and therefore obsolete, so it will be among the singleton nodes. These oddities *may* have an impact on the value of the graph embeddings we'll assemble in the next section and they *may* highlight areas where our data is structured in ways we may not expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph.from_csv(\n",
    "  directed=False, # This is a directed graph - we're treating it as undirected to make it easier to examine paths.\n",
    "  node_path='merged-kg_nodes.tsv',\n",
    "  edge_path='merged-kg_edges.tsv',\n",
    "  verbose=True,\n",
    "  nodes_column='id',\n",
    "  node_list_node_types_column='category',\n",
    "  default_node_type='biolink:NamedThing',\n",
    "  sources_column='subject',\n",
    "  destinations_column='object',\n",
    "  edge_list_edge_types_column='predicate',\n",
    "  name=\"A Graph of Foods\"\n",
    ")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942957e",
   "metadata": {},
   "source": [
    "Now let's try to find all edges connecting nodes to a DNA repair pathway. The human DNA repair pathway as an ID of **R-HSA-73894** in Reactome, so in our graph it will have an identifier of **REACT:R-HSA-73894**. We can run the following to find all related edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step = g.get_neighbour_node_names_from_node_name(node_name=\"REACT:R-HSA-73894\")\n",
    "one_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4285d",
   "metadata": {},
   "source": [
    "So this pathway only has other Reactome pathways as neighbors. That's fine - we can check for neighbors of those neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step = []\n",
    "for neighbor in one_step:\n",
    "    for result in g.get_neighbour_node_names_from_node_name(node_name=neighbor):\n",
    "        two_step.append(result)\n",
    "two_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f9f12",
   "metadata": {},
   "source": [
    "Now things are getting interesting. Several of these nodes are CHEBI entries. These aren't drugs or environmental contaiminants, though: they're participants in the pathways, like CHEBI:16991 - that's just [DNA](https://www.ebi.ac.uk/ols/ontologies/chebi/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FCHEBI_16991).\n",
    "\n",
    "We can see the whole path, in terms of the names of nodes in that path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3093fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_shortest_path_node_names_from_node_names(src_node_name=\"REACT:R-HSA-73894\", dst_node_name=\"CHEBI:456216\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74c5a7",
   "metadata": {},
   "source": [
    "Using the same strategy, we can see if there are other paths of interest.\n",
    "\n",
    "Let's get a set of all FOODON entries and see if any of them have paths back to the DNA Repair pathway node. This will take a short while. We're also most interested in the _shortest_ paths, so we'll sort the paths by length and look at the shortest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nodes = []\n",
    "for result in g.get_node_names():\n",
    "    if result.startswith(\"FOODON\"):\n",
    "        food_nodes.append(result)\n",
    "\n",
    "print(f\"Found {len(food_nodes)} nodes from FOODON.\")\n",
    "\n",
    "food_paths = []\n",
    "for node in food_nodes:\n",
    "    try:\n",
    "        path = g.get_shortest_path_node_names_from_node_names(src_node_name=\"REACT:R-HSA-73894\", dst_node_name=node)\n",
    "        food_paths.append(path)\n",
    "    except ValueError:\n",
    "        # This means there isn't a path to the destination from the specified node\n",
    "        continue\n",
    "\n",
    "food_paths.sort(key=len)\n",
    "print(food_paths[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf747600",
   "metadata": {},
   "source": [
    "You can expect to find a few paths of length 5, at least. I'll spoil one of them:\n",
    "\n",
    "`['REACT:R-HSA-73894', 'REACT:R-HSA-73942', 'REACT:R-HSA-73943', 'CHEBI:16526', 'FOODON:03301011']`\n",
    "is a path from the DNA Repair pathway to the DNA Damage Reversal pathway to the \"Reversal of alkylation damage by DNA dioxygenases\" pathway which involves carbon dioxide (CHEBI:16526) as a component, as do carbonated beverages (FOODON:03301011). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ngMKIcWZ41K",
   "metadata": {
    "id": "8ngMKIcWZ41K"
   },
   "source": [
    "## Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fa230",
   "metadata": {},
   "source": [
    "GraPE is particularly efficient at preparing graph embeddings. \n",
    "Let's see a list of its available node embedding methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import get_available_models_for_node_embedding\n",
    "get_available_models_for_node_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6bfda",
   "metadata": {},
   "source": [
    "Let's use Ensmallen's implementation of a method named [HOPE](https://www.kdd.org/kdd2016/papers/files/rfp0184-ouA.pdf). For the sake of simplicity, we'll specify the metric as 'Adjacency' below. We'll also set `enable_cache` to true so the embeddings get saved locally (in the current working directory, under `/embedding/HOPE/Ensmallen/[name of the graph]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53de444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.embedders import HOPEEnsmallen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db341a6",
   "metadata": {},
   "source": [
    "Remove disconnected nodes first, as they won't contribute much to our embeddings and may cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f15067",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.remove_disconnected_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HOPEEnsmallen(metric=\"Adjacency\",enable_cache=True)\n",
    "embedding = model.fit_transform(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f96da",
   "metadata": {},
   "source": [
    "Now let's see what those embeddings look like. They won't be too informative just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.get_node_embedding_from_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ccaad",
   "metadata": {},
   "source": [
    "Now we'll create some plots. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d59803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import GraphVisualizer\n",
    "visualizer = GraphVisualizer(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87553354",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.fit_and_plot_all(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd6b54",
   "metadata": {},
   "source": [
    "These plots primarily serve to show how the graph contents may be separated based on the newly created embeddings. Ideally, we'd like there to be a clear feature distinguishing existing vs non-existing edges, or it will be difficult to predict which new edges may be likely to exist. Different embeddings and metrics are likely to correlate with potentially useful features, but there is no guarantee that any one feature will be sufficient for consistently predicting new edges.\n",
    "\n",
    "We can pass an embedding method by name, too - try the plot specified below and compare with the results above. Or, continue to the next section to see how to predict new edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c129d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GraphVisualizer(g)\n",
    "visualizer.fit_and_plot_all(\"NetMF\",iterations=1,walk_length=5,embedding_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ZjgrmtXZ77C",
   "metadata": {
    "id": "3ZjgrmtXZ77C"
   },
   "source": [
    "## Edge Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228e19f",
   "metadata": {},
   "source": [
    "We may finally try to predict some new edges between foods and pathways. As we saw above, there are no paths directly between only these two types of nodes. Instead, we can attempt to find new potential relationships between all nodes in the graph.\n",
    "\n",
    "At this point we'll just need to work with the largest fully connected component of the graph, as our methods won't work if all our nodes aren't connected to each other in some way. Let's see how many components are in the graph right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_number_of_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77414099",
   "metadata": {},
   "source": [
    "The displayed triple tells us the total number of components, the size of the smallest component in nodes, and the size of the largest component in nodes, respectively. Most importantly, there's more than one component in there. Let's trim it down to just the component containing our pathway of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_g = g.remove_components(node_names=['REACT:R-HSA-73894'])\n",
    "trim_g.get_number_of_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478aaed4",
   "metadata": {},
   "source": [
    "That's better - we should have just one component now. We have a few options regarding next steps:\n",
    "*  We can use the node embeddings to train a model and apply the model to generate predicted edges. This will rely upon the topology of the graph. In practice, NEAT will run this entire pipeline, from graph loading to edge prediction, based on a single config file (see the Machine Learning on Knowledge Graphs tutorial notebook for an example). We'll skip that here as we've already done some of the work.\n",
    "* We can get node features based on their text with a BERT model.\n",
    "* We can use a node feature such as its category. Our graph doesn't have too many different sources and we haven't specified detailed categories, so this may not be very informative here.\n",
    "* We can use edge features.\n",
    "\n",
    "First, let's see some of the edge prediction methods we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import get_available_models_for_edge_prediction\n",
    "get_available_models_for_edge_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369eb21e",
   "metadata": {},
   "source": [
    "### Perceptron and Edge Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34b0cd",
   "metadata": {},
   "source": [
    "The next step will evaluate how well Ensmallen's Perceptron model implementation works on edge prediction. Note that this doesn't include any embedding-derived features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a644c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embiggen.edge_prediction.edge_prediction_ensmallen.perceptron import PerceptronEdgePrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7de060",
   "metadata": {},
   "source": [
    "We assemble train and test subgraphs, with an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = trim_g.connected_holdout(train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd29ce",
   "metadata": {},
   "source": [
    "Get an embedding of the training graph. As before, this may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HOPEEnsmallen(metric=\"Adjacency\").fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732c299",
   "metadata": {},
   "source": [
    "Next, we train the model. Also a potentially time-consuming process, but I assume you're patient and/or have other things to occupy your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PerceptronEdgePrediction(\n",
    "    edge_features=None,\n",
    "    number_of_edges_per_mini_batch=16,\n",
    "    edge_embeddings=\"CosineSimilarity\"\n",
    ")\n",
    "model.fit(\n",
    "    graph=train, \n",
    "    node_features=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39f025",
   "metadata": {},
   "source": [
    "With the newly trained model, we may now provide it the nodes in our test set and see how good it is at predicting them. Each of these edges already exist, so we expect to see many high confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict_proba(\n",
    "    graph=test,\n",
    "    node_features=embedding,\n",
    "    return_predictions_dataframe=True\n",
    ")\n",
    "hist = test_pred.hist(bins=100,\n",
    "                       color=\"darkgreen\",\n",
    "                       column=\"predictions\", \n",
    "                       xlabelsize = 14,\n",
    "                       ylabelsize = 14,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ee09b",
   "metadata": {},
   "source": [
    "That's not really *prediction*, though. Let's predict some new edges! To do so, we just need a negative set of potential edges, then repeat the process as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992982",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_graph = trim_g.sample_negative_graph(number_of_negative_samples=test.get_number_of_edges())\n",
    "pred = model.predict_proba(\n",
    "    graph=negative_graph,\n",
    "    node_features=embedding,\n",
    "    return_predictions_dataframe=True\n",
    ")\n",
    "hist = pred.hist(bins=100,\n",
    "                       color=\"orange\",\n",
    "                       column=\"predictions\", \n",
    "                       xlabelsize = 14,\n",
    "                       ylabelsize = 14,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b6744",
   "metadata": {},
   "source": [
    "There's a possibility that some of our negative edges are in the original graph since we did some trimming. Let's remove all the existing edges from the results and sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sources\", \"destinations\"]\n",
    "\n",
    "# Remove all existing edges\n",
    "all_edge_node_names = trim_g.get_edge_node_names(directed=False)\n",
    "pred = pred[~pred[cols].apply(tuple, 1).isin(all_edge_node_names)]\n",
    "\n",
    "# Remove self-interactions\n",
    "pred = pred[pred['sources'] != pred['destinations']]\n",
    "\n",
    "# Sort\n",
    "pred.sort_values(by=['predictions'], ascending=False, inplace=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747cdd75",
   "metadata": {},
   "source": [
    "These scores may not be as high as they could be, so some further optimization may be in order. \n",
    "\n",
    "Before we forget about our use case, let's see which of these predictions involve one of the 1-hop or 2-hop neighbors of our focus pathway, REACT:R-HSA-73894."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = one_step + two_step\n",
    "pred = pred[(pred['sources'].str.contains('|'.join(neighbors)))|(pred['destinations'].str.contains('|'.join(neighbors)))]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181aaafb",
   "metadata": {},
   "source": [
    "If you see `FOODON:03309530`, that's the entry for \"muffin\". I'm afraid I won't be able to explain how or why a muffin may impact DNA repair.\n",
    "\n",
    "We may also filter by prefix when obtaining predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba_bipartite_graph_from_edge_node_prefixes(\n",
    "    graph=negative_graph,\n",
    "    node_features=embedding,\n",
    "    return_predictions_dataframe=True,\n",
    "    source_node_prefixes=[\"REACT\"],\n",
    "    destination_node_prefixes=[\"CHEBI\"]\n",
    ")\n",
    "\n",
    "cols = [\"sources\", \"destinations\"]\n",
    "\n",
    "# Process as before.\n",
    "all_edge_node_names = trim_g.get_edge_node_names(directed=False)\n",
    "pred = pred[~pred[cols].apply(tuple, 1).isin(all_edge_node_names)]\n",
    "\n",
    "pred = pred[pred['sources'] != pred['destinations']]\n",
    "\n",
    "pred.sort_values(by=['predictions'], ascending=False, inplace=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc62d1",
   "metadata": {},
   "source": [
    "### Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d2c23",
   "metadata": {},
   "source": [
    "Let's see if the names and descriptions of the nodes in our graph contain features useful for edge prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.datasets import get_okapi_tfidf_weighted_textual_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_okapi_tfidf_weighted_textual_embedding('merged-kg_nodes.tsv',\n",
    "                                                       separator = \"\\t\",\n",
    "                                                       header = True,\n",
    "                                                      columns=[\"name\",\"description\"],\n",
    "                                                      verbose = True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120f433",
   "metadata": {},
   "source": [
    "We convert the embeddings to a dataframe so they can be mapped to the subset of nodes in our trimmed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c333f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.DataFrame(embedding, index=g.get_node_names())\n",
    "subgraph_bert_df = bert_df.loc[trim_g.get_node_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41358a89",
   "metadata": {},
   "source": [
    "Now let's plot those BERT embeddings to see what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfe40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GraphVisualizer(trim_g)\n",
    "visualizer.fit_and_plot_all(subgraph_bert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc810dbf",
   "metadata": {},
   "source": [
    "The results are not obviously useful. There isn't a clear distinction between existing and non-existing edges. That being said, we can still pass them on to a model to see if we can get any useful edge predictions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Advanced Knowledge Graph Assembly",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
